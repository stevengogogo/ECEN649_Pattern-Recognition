{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5feb78ff-3888-4f8e-8e1d-55b6e188970c",
   "metadata": {},
   "source": [
    "{{< include hw4.qmd >}}\n",
    "\n",
    "## Problem 6.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315daa55-b97c-4e74-95a1-6549ea084bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL\n",
    "import cv2\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import platform\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d98b1c-ba8e-47eb-b1d9-261a14842eaf",
   "metadata": {},
   "source": [
    "### Computational Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfca9c7-3f56-487b-8030-822c357fad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "my_system = platform.uname()\n",
    "print(physical_devices)\n",
    "print(f\"System: {my_system.system}\")\n",
    "print(f\"Node Name: {my_system.node}\")\n",
    "print(f\"Release: {my_system.release}\")\n",
    "print(f\"Version: {my_system.version}\")\n",
    "print(f\"Machine: {my_system.machine}\")\n",
    "print(f\"Processor: {my_system.processor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a764a-3d02-4cf3-b4e4-ee0860f51c43",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b7f11-df46-468d-92ea-a1c8f294dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, width=484, preprocess_input=tf.keras.applications.vgg16.preprocess_input):\n",
    "    \"\"\"\n",
    "    Load and Preprocessing image\n",
    "    \"\"\"\n",
    "    img = tf.keras.utils.load_img(path)\n",
    "    x = tf.keras.utils.img_to_array(img)\n",
    "    x = x[0:width,:,:]\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return tf.keras.applications.vgg16.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d6b38-4f4f-4336-957a-20a2fd259007",
   "metadata": {},
   "source": [
    "### Data inspectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1edca3-9cf4-4a1c-b1f2-03cba758f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = os.path.join(\"data\", \"CMU-UHCS_Dataset\")\n",
    "pic_path = os.path.join(dpath, \"images\")\n",
    "df_micro = pd.read_csv( os.path.join(dpath, \"micrograph.csv\"))\n",
    "df_micro = df_micro[[\"path\", \"primary_microconstituent\"]]\n",
    "\n",
    "for i in range(0, len(df_micro)):\n",
    "    img_ph = os.path.join(pic_path,df_micro.iloc[i][0])\n",
    "    assert os.path.exists(img_ph)\n",
    "    df_micro.iloc[i][0] = img_ph\n",
    "df_micro2 = df_micro.copy()\n",
    "CLS_rm = [\"pearlite+widmanstatten\", \"martensite\", \"pearlite+spheroidite\"] #(type, sample size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca315dad-5c16-4caf-a0a8-05232c0c16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in CLS_rm:\n",
    "    df_micro.drop(df_micro[df_micro[\"primary_microconstituent\"] == c].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae27cb6-ed67-4d40-800a-409ec64fff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "name_lbs = df_micro[\"primary_microconstituent\"].unique()\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(name_lbs)\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c2ed4-0d2f-4df8-a11e-7acc2c8139da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlabel = le.transform(df_micro[\"primary_microconstituent\"])\n",
    "df_micro.insert(2, \"label\", dlabel)\n",
    "df_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29623ffc-3d4c-4d45-a0ad-7e04749d8907",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20239b1-9f89-4321-aeea-1bbcbff23f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "df_test = df_micro.copy()\n",
    "df_train = pd.DataFrame(columns = df_micro.keys())\n",
    "\n",
    "split_info = [(\"spheroidite\", 100),\\\n",
    "              (\"network\", 100),\\\n",
    "              (\"pearlite\", 100),\\\n",
    "              (\"spheroidite+widmanstatten\", 60)] #(type, sample size)\n",
    "\n",
    "\n",
    "\n",
    "for ln in split_info:\n",
    "    label, n = ln\n",
    "    id_train = df_micro[df_micro[\"primary_microconstituent\"] == label][0:n].index\n",
    "    df_test.drop(id_train, axis=0, inplace=True)\n",
    "    df_train = pd.concat([df_train, df_micro.loc[id_train]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc8830-9af8-40c3-ad71-480c0cf60045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e039d84-aea2-4ef9-bda9-34486308768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724aac0-79eb-4a6a-a69c-91add6320e60",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bf805-ac41-4da8-8d56-47764559f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16\n",
    "\n",
    "base_model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97f25f-844c-48c5-b581-c962fe722be7",
   "metadata": {},
   "source": [
    "Use five layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d52c02-08ac-4551-9997-315133304b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_layer_ns = [\"block{}_pool\".format(i) for i in range(1,6)]\n",
    "out_layer_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5204dd-bc48-44cc-8d0a-2d6c44be736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct 5 models for feature extraction\n",
    "extmodel = dict(zip(out_layer_ns, [tf.keras.Model(\n",
    "    inputs= base_model.input,\n",
    "    outputs=base_model.get_layer(bk_name).output\n",
    ") for bk_name in out_layer_ns]))\n",
    "\n",
    "extmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b31a8-813c-4614-8c13-0068e62a1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display output dimensions\n",
    "out_shapes = [extmodel[m].output_shape[-1] for m in extmodel.keys()]\n",
    "out_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa7357-7d7e-4448-b3e9-a3fd26de16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate feature maps for testing and training\n",
    "fs_train = [np.zeros((df_train.shape[0], n_f)) for n_f in out_shapes]\n",
    "fs_test = [np.zeros((df_test.shape[0], n_f)) for n_f in out_shapes]\n",
    "\n",
    "features_train = dict(zip(out_layer_ns, fs_train))\n",
    "features_test = dict(zip(out_layer_ns, fs_test))\n",
    "\n",
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d50cca-be63-4ae4-9a2e-ecc4b46841be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction with VGG16\n",
    "if os.path.exists(os.path.join(dpath, \"feature_train.pkl\")) == False:\n",
    "    for m in tqdm(extmodel.keys()):\n",
    "        for i, df in enumerate([df_train, df_test]):\n",
    "            for j, ph in tqdm(enumerate(df[\"path\"])):\n",
    "                x = load_image(ph)\n",
    "                xb = extmodel[m].predict(x, verbose = 0) # silence output\n",
    "                F = np.mean(xb,axis=(0,1,2))\n",
    "                # Save features\n",
    "                if i ==0:\n",
    "                    features_train[m][j, :] = F\n",
    "                else:\n",
    "                    features_test[m][j, :] = F\n",
    "    #save file\n",
    "    paths =  dict(zip([\"train\", \"test\"],\\\n",
    "        [os.path.join(dpath, \"feature_{}.pkl\".format(n))\\\n",
    "         for n in [\"train\", \"test\"]]))\n",
    "    ## Create new files\n",
    "    f_train = open(paths[\"train\"], \"wb\")\n",
    "    f_test = open(paths[\"test\"], \"wb\")\n",
    "    ## Write\n",
    "    pickle.dump(features_train, f_train)\n",
    "    pickle.dump(features_test, f_test)\n",
    "    ## Close files\n",
    "    f_train.close()\n",
    "    f_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6087f3-1c24-4602-8d3e-c6fdcabd8bd5",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc07fd1-7334-4974-b755-bee0a9ef3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ftn = open(paths[\"train\"], \"rb\")\n",
    "ftt = open(paths[\"test\"], \"rb\")\n",
    "featn = pickle.load(ftn) # train feature\n",
    "featt = pickle.load(ftt) # test feature\n",
    "ftn.close()\n",
    "ftt.close()\n",
    "\n",
    "# label\n",
    "ltrain = df_train[[\"primary_microconstituent\", \"label\"]].reset_index()\n",
    "ltest = df_test[[\"primary_microconstituent\", \"label\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04379861-3ea4-4533-9f21-5ec1e47dbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7458b-d24f-47d4-a58b-b3eb5fcbe9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltest[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64e065-5c8d-4348-a366-51b7da4516c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "featn[\"block1_pool\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac7a88-5bf9-4613-b954-0fb8302a967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"label\"].to_numpy().astype(int)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9888230-b073-493c-8924-dc680c729f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"rbf\", C=1., gamma=\"auto\")\n",
    "clf.fit(featn[\"block1_pool\"], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e128646-d148-4307-825a-5bdc535e11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(featt[\"block1_pool\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5bf26-ac85-47b3-9306-ea3d90ecf042",
   "metadata": {},
   "source": [
    "#### One-to-One SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e10709-f9a9-4145-a5d9-7e65813bbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class One2OneSVM:\n",
    "    def __init__(self, n_class=4):\n",
    "        self.n_class = n_class\n",
    "        self.clfs = [[svm.SVC(kernel=\"rbf\", C=1., gamma=\"auto\")\\\n",
    "                     for i in range(0,self.n_class)]\\\n",
    "                     for j in range(0,self.n_class)]\n",
    "        self.cv = np.zeros((self.n_class,self.n_class))\n",
    "    def train(self, ltrain, feature, fold=10):\n",
    "        # traversal all features\n",
    "        for i in range(0, self.n_class-1):\n",
    "            lis = ltrain[ltrain[\"label\"] == i].index.to_numpy()\n",
    "            for j in range(i+1, self.n_class):\n",
    "                ljs = ltrain[ltrain[\"label\"] == j].index.to_numpy()\n",
    "                # Data\n",
    "                X = np.concatenate(\\\n",
    "                  (feature[lis,:],\\\n",
    "                   feature[ljs,:]), axis=0)\n",
    "                Y = np.concatenate((np.ones(len(lis))*i,np.ones(len(ljs))*j))\n",
    "                # Train SVM\n",
    "                scores = sklearn.model_selection.cross_val_score(self.clfs[i][j], X, Y, cv=fold)\n",
    "                self.clfs[i][j].fit(X,Y)\n",
    "                self.cv[i][j] = np.max(scores)\n",
    "                \n",
    "    def test_1v1_error(self, ltest, feature):\n",
    "        # traversal all features\n",
    "        errM = np.zeros((self.n_class, self.n_class))\n",
    "        for i in range(0, self.n_class-1):\n",
    "            lis = ltest[ltest[\"label\"] == i].index.to_numpy()\n",
    "            for j in range(i+1, self.n_class):\n",
    "                ljs = ltest[ltest[\"label\"] == j].index.to_numpy()\n",
    "                # Data\n",
    "                X = np.concatenate(\\\n",
    "                  (feature[lis,:],\\\n",
    "                   feature[ljs,:]), axis=0)\n",
    "                Y = np.concatenate((np.ones(len(lis))*i,np.ones(len(ljs))*j))\n",
    "                # Train SVM\n",
    "                y_pred = self.clfs[i][j].predict(X)\n",
    "                errM[i,j] = error(Y, y_pred)\n",
    "        return errM\n",
    "        \n",
    "    def predict(self, feature):\n",
    "        predM = np.zeros(( int(self.n_class * (self.n_class -1)/2) , feature.shape[0]))\n",
    "        c = 0\n",
    "        for i in range(0, self.n_class-1):\n",
    "            for j in range(i+1, self.n_class):\n",
    "                predM[c,:] = self.clfs[i][j].predict(feature)\n",
    "                c += 1\n",
    "        return st.mode(predM, axis=0, keepdims=True).mode[0,:] #majority voting\n",
    "\n",
    "def error(ans, pred):\n",
    "    assert len(ans) == len(pred)\n",
    "    return (ans != pred).sum()/float(ans.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279afeaf-bfe4-4245-92b0-e1ac2e0b3c82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (a)\n",
    "> The convolution layer used and the cross-validated error estimate for each of the six\n",
    "pairwise two-label classifiers\n",
    "\n",
    "\n",
    "### (b)\n",
    "\n",
    "> Separate test error rates on the unused micrographs of each of the four categories, for\n",
    "the pairwise two-label classifiers and the multilabel one-vs-one voting classifier described\n",
    "previously. For the pairwise classifiers use only the test micrographs with the two labels\n",
    "used to train the classifier. For the multilabel classifier, use the test micrographs with\n",
    "the corresponding four labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9759d-931e-4776-8bf4-56532aed8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cv(m, clf, info=\"\"):\n",
    "    var1 = []\n",
    "    var2 = []\n",
    "    cvs = []\n",
    "    errs = []\n",
    "    for i in range(0, m.shape[0]-1):\n",
    "        for j in range(i+1, m.shape[0]):\n",
    "            var1.append(i)\n",
    "            var2.append(j)\n",
    "            cvs.append(clf.cv[i,j])\n",
    "            errs.append(m[i,j])\n",
    "    infos = [info] * len(errs)\n",
    "    return pd.DataFrame({\"Info\": infos, \"Label 1\": var1, \"Label 2\": var2, \"Test error\": errs,\"Cross Validation Score\": cvs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20555bd-387e-4578-96de-2914e092d3af",
   "metadata": {},
   "source": [
    "#### Pair-wise classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b509df-fdfa-4136-9dcd-72743a32f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errors = []\n",
    "for b in out_layer_ns:\n",
    "    clf1 = One2OneSVM()\n",
    "    clf1.train(ltrain, features_train[b])\n",
    "    errs = clf1.test_1v1_error(ltest, features_test[b])\n",
    "    df_errors.append(df_cv(errs, clf1, b))\n",
    "    \n",
    "res_error = pd.concat(df_errors)\n",
    "res_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53f9db-a503-4ed9-ac4f-16da65015c72",
   "metadata": {},
   "source": [
    "#### Multiple one-vs-one classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a65c6-30d2-4f10-b82c-1c0a05e6ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass one-vs-one\n",
    "dfm_errors = []\n",
    "for b in out_layer_ns:\n",
    "    clf = OneVsOneClassifier(svm.SVC(kernel=\"rbf\", C=1., gamma=\"auto\").fit(features_train[b],\\\n",
    "          ltrain[\"label\"].to_numpy(int)))\n",
    "    clf.fit(features_train[b],\\\n",
    "          ltrain[\"label\"].to_numpy(int))\n",
    "    y_predm = clf.predict(features_test[b])\n",
    "    dfm_errors.append(1 - error(y_predm, ltest[\"label\"].to_numpy()))\n",
    "\n",
    "# Display result\n",
    "res_multi1v1 = pd.DataFrame({\"Info\": out_layer_ns, \"Score\": dfm_errors})\n",
    "res_multi1v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e45ce-cec3-440d-a003-9ac90fbba868",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "> For the mixed pearlite + spheroidite test micrographs, apply the trained pairwise classifier\n",
    "for pearlite vs. spheroidite and the multilabel voting classifier. Print the predicted labels\n",
    "by these two classifiers side by side (one row for each test micrograph). Comment your\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a00f59-8415-45bd-84e9-9600cff6564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltestm = ltest[(ltest[\"primary_microconstituent\"] == \"pearlite\") |\\\n",
    "      (ltest[\"primary_microconstituent\"] == \"spheroidite\")]\n",
    "feature_m = features_test[\"block5_pool\"][ltestm.index.to_numpy(), :]\n",
    "l = le.transform([\"pearlite\", \"spheroidite\"])\n",
    "\n",
    "pred_pairs = clf1.clfs[l[0]][l[1]].predict(feature_m)\n",
    "pred_multi = clf.predict(feature_m)\n",
    "\n",
    "res_ps = pd.DataFrame({\"Test Label\": le.inverse_transform(ltestm[\"label\"]),\\\n",
    "              \"Pairwise (pearlite vs. spheroidite)\": le.inverse_transform(pred_pairs.astype(int)),\\\n",
    "              \"Multi-OnevsOne\": le.inverse_transform(pred_multi)})\n",
    "\n",
    "print(res_ps.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22736d-dfcc-42ff-92ce-2dcd72d84126",
   "metadata": {},
   "source": [
    "### (d)\n",
    "\n",
    "> Now apply the multilabel classifier on the pearlite + WidmanstÂ¨atten and martensite\n",
    "micrographs and print the predicted labels. Compare to the results in part (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbd3b8-6470-4afd-adf0-ba310fe78247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_micro2 = df_micro2[(df_micro2[\"primary_microconstituent\"] == \"pearlite+widmanstatten\") |\\\n",
    "(df_micro2[\"primary_microconstituent\"] == \"martensite\")]\n",
    "\n",
    "# Encode labels\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(df_micro2[\"primary_microconstituent\"].unique())\n",
    "list(le2.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad26ad9-0bbb-4c2c-8682-60f512022f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlabel2 = le2.transform(df_micro2[\"primary_microconstituent\"])\n",
    "df_micro2.insert(2, \"label\", dlabel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e619e-0e12-4f4c-bdc4-a67018b2fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_micro2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129305d-64bc-428c-996a-6e3425b7c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction with VGG16\n",
    "if os.path.exists(os.path.join(dpath, \"feature_test2.pkl\")) == False:\n",
    "    fs_test2 = np.zeros((df_micro2.shape[0], out_shapes[-1]))\n",
    "    m = \"block5_pool\"\n",
    "    for j, ph in tqdm(enumerate(df_micro2[\"path\"])):\n",
    "        x = load_image(ph)\n",
    "        xb = extmodel[m].predict(x, verbose = 0) # silence output\n",
    "        F = np.mean(xb,axis=(0,1,2))\n",
    "        # Save features\n",
    "        fs_test2[j, :] = F\n",
    "\n",
    "    # Save data\n",
    "    ## Create new files\n",
    "    fs_test2_p = open(os.path.join(dpath, \"feature_test2.pkl\"), \"wb\")\n",
    "    ## Write\n",
    "    pickle.dump(fs_test2, fs_test2_p)\n",
    "    ## Close files\n",
    "    fs_test2_p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5cde76-bf4f-43a4-beee-49407519566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "fs_test2_p  = open(os.path.join(dpath, \"feature_test2.pkl\"), \"rb\")\n",
    "fs_test2 = pickle.load(fs_test2_p) # train feature\n",
    "fs_test2_p .close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2ce6c-c0a4-4301-a8d7-b55ab6724d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_multi2 = clf.predict(fs_test2)\n",
    "\n",
    "res_ps2 = pd.DataFrame({\"Test Label\": le2.inverse_transform(df_micro2[\"label\"]),\\\n",
    "              \"Multi-OnevsOne\": le.inverse_transform(pred_multi2)})\n",
    "\n",
    "print(res_ps2.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
